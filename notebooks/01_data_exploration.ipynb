{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 📊 Data Exploration Tutorial\n",
    "\n",
    "Welcome to the first tutorial in our ML Pipeline series! In this notebook, we'll explore our datasets and understand their characteristics.\n",
    "\n",
    "## 🎯 What You'll Learn\n",
    "- How to load and examine datasets\n",
    "- Understanding data distributions and patterns\n",
    "- Identifying missing values and outliers\n",
    "- Creating visualizations for data insights\n",
    "- Generating data quality reports\n",
    "\n",
    "## 📚 Datasets We'll Explore\n",
    "1. **Titanic Dataset** - Passenger survival prediction (Classification)\n",
    "2. **Boston Housing Dataset** - House price prediction (Regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🛠️ Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# UNIVERSAL SETUP - Works on all PCs and environments\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Navigate to project root if we're in notebooks directory\n",
    "if os.getcwd().endswith('notebooks'):\n",
    "    os.chdir('..')\n",
    "    print(f\"📁 Changed to project root: {os.getcwd()}\")\n",
    "else:\n",
    "    print(f\"📁 Already in project root: {os.getcwd()}\")\n",
    "\n",
    "# Add src to Python path\n",
    "src_path = os.path.join(os.getcwd(), 'src')\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "    print(f\"📦 Added to Python path: {src_path}\")\n",
    "\n",
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "# Import our custom modules\n",
    "try:\n",
    "    from data.data_loader import DataLoader\n",
    "    from data.data_validator import DataValidator\n",
    "    print(\"✅ Custom modules imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"⚠️ Import error: {e}\")\n",
    "    print(\"💡 Make sure you're running from the project root directory\")\n",
    "\n",
    "# Configure plotting\n",
    "try:\n",
    "    plt.style.use('seaborn-v0_8')\n",
    "except:\n",
    "    plt.style.use('seaborn')  # Fallback for older versions\n",
    "\n",
    "sns.set_palette(\"husl\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set display options\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Verify data files exist\n",
    "data_files = ['data/raw/titanic.csv', 'data/raw/housing.csv']\n",
    "missing_files = []\n",
    "for file in data_files:\n",
    "    if Path(file).exists():\n",
    "        print(f\"✅ {file} found\")\n",
    "    else:\n",
    "        missing_files.append(file)\n",
    "        print(f\"❌ {file} missing\")\n",
    "\n",
    "if missing_files:\n",
    "    print(\"\\n🔧 Missing data files detected. Run this to fix:\")\n",
    "    print(\"   python download_datasets.py\")\n",
    "else:\n",
    "    print(\"\\n🎉 All data files found! Ready to proceed.\")\n",
    "\n",
    "print(\"✅ Setup completed successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📥 Load Datasets\n",
    "\n",
    "First, let's load our datasets using our custom DataLoader class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DATA LOADING - Universal approach with error handling\n",
    "# =============================================================================\n",
    "\n",
    "# Initialize data loader\n",
    "try:\n",
    "    loader = DataLoader()\n",
    "    print(\"📊 DataLoader initialized successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ DataLoader initialization failed: {e}\")\n",
    "    # Fallback: load data directly\n",
    "    print(\"🔄 Using direct pandas loading as fallback...\")\n",
    "\n",
    "# Load datasets with error handling\n",
    "print(\"\\n📥 Loading datasets...\")\n",
    "\n",
    "# Load Titanic dataset\n",
    "try:\n",
    "    if 'loader' in locals():\n",
    "        titanic_data = loader.load_titanic()\n",
    "    else:\n",
    "        titanic_data = pd.read_csv('data/raw/titanic.csv')\n",
    "    \n",
    "    if not titanic_data.empty:\n",
    "        print(f\"✅ Titanic dataset loaded: {titanic_data.shape}\")\n",
    "    else:\n",
    "        print(\"⚠️ Titanic dataset is empty\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load Titanic dataset: {e}\")\n",
    "    titanic_data = pd.DataFrame()  # Empty DataFrame as fallback\n",
    "\n",
    "# Load Housing dataset\n",
    "try:\n",
    "    if 'loader' in locals():\n",
    "        housing_data = loader.load_housing()\n",
    "    else:\n",
    "        housing_data = pd.read_csv('data/raw/housing.csv')\n",
    "    \n",
    "    if not housing_data.empty:\n",
    "        print(f\"✅ Housing dataset loaded: {housing_data.shape}\")\n",
    "    else:\n",
    "        print(\"⚠️ Housing dataset is empty\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to load Housing dataset: {e}\")\n",
    "    housing_data = pd.DataFrame()  # Empty DataFrame as fallback\n",
    "\n",
    "# Summary\n",
    "if not titanic_data.empty and not housing_data.empty:\n",
    "    print(\"\\n🎉 Both datasets loaded successfully!\")\n",
    "elif titanic_data.empty and housing_data.empty:\n",
    "    print(\"\\n❌ Both datasets failed to load. Please run: python download_datasets.py\")\n",
    "else:\n",
    "    print(\"\\n⚠️ One dataset loaded successfully, one failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🚢 Titanic Dataset Exploration\n",
    "\n",
    "Let's start by exploring the famous Titanic dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🚢 TITANIC DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {titanic_data.shape}\")\n",
    "print(f\"Columns: {list(titanic_data.columns)}\")\n",
    "print(\"\\n📊 Data Types:\")\n",
    "print(titanic_data.dtypes)\n",
    "print(\"\\n📈 Basic Statistics:\")\n",
    "titanic_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"👀 First 5 rows of Titanic dataset:\")\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Target Variable Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze survival rates\n",
    "survival_counts = titanic_data['Survived'].value_counts()\n",
    "survival_rates = titanic_data['Survived'].value_counts(normalize=True) * 100\n",
    "\n",
    "print(\"🎯 SURVIVAL ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "print(f\"Survived (1): {survival_counts[1]} passengers ({survival_rates[1]:.1f}%)\")\n",
    "print(f\"Did not survive (0): {survival_counts[0]} passengers ({survival_rates[0]:.1f}%)\")\n",
    "\n",
    "# Visualize survival distribution\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Bar plot\n",
    "survival_counts.plot(kind='bar', ax=ax1, color=['red', 'green'])\n",
    "ax1.set_title('Survival Count')\n",
    "ax1.set_xlabel('Survived (0=No, 1=Yes)')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(survival_counts.values, labels=['Did not survive', 'Survived'], \n",
    "        autopct='%1.1f%%', colors=['red', 'green'])\n",
    "ax2.set_title('Survival Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🚻 Demographic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender analysis\n",
    "print(\"🚻 GENDER ANALYSIS\")\n",
    "print(\"=\" * 20)\n",
    "gender_survival = pd.crosstab(titanic_data['Sex'], titanic_data['Survived'], margins=True)\n",
    "print(gender_survival)\n",
    "\n",
    "# Calculate survival rates by gender\n",
    "gender_survival_rate = pd.crosstab(titanic_data['Sex'], titanic_data['Survived'], normalize='index') * 100\n",
    "print(\"\\n📊 Survival Rates by Gender:\")\n",
    "print(gender_survival_rate)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "gender_survival.iloc[:-1, :-1].plot(kind='bar', stacked=True, ax=ax1, color=['red', 'green'])\n",
    "ax1.set_title('Survival by Gender (Count)')\n",
    "ax1.set_xlabel('Gender')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.legend(['Did not survive', 'Survived'])\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Survival rate by gender\n",
    "gender_survival_rate[1].plot(kind='bar', ax=ax2, color='green')\n",
    "ax2.set_title('Survival Rate by Gender')\n",
    "ax2.set_xlabel('Gender')\n",
    "ax2.set_ylabel('Survival Rate (%)')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎫 Passenger Class Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class analysis\n",
    "print(\"🎫 PASSENGER CLASS ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "class_survival = pd.crosstab(titanic_data['Pclass'], titanic_data['Survived'], margins=True)\n",
    "print(class_survival)\n",
    "\n",
    "# Calculate survival rates by class\n",
    "class_survival_rate = pd.crosstab(titanic_data['Pclass'], titanic_data['Survived'], normalize='index') * 100\n",
    "print(\"\\n📊 Survival Rates by Class:\")\n",
    "print(class_survival_rate)\n",
    "\n",
    "# Visualize\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "# Stacked bar chart\n",
    "class_survival.iloc[:-1, :-1].plot(kind='bar', stacked=True, ax=ax1, color=['red', 'green'])\n",
    "ax1.set_title('Survival by Passenger Class (Count)')\n",
    "ax1.set_xlabel('Passenger Class')\n",
    "ax1.set_ylabel('Count')\n",
    "ax1.legend(['Did not survive', 'Survived'])\n",
    "ax1.tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Survival rate by class\n",
    "class_survival_rate[1].plot(kind='bar', ax=ax2, color='blue')\n",
    "ax2.set_title('Survival Rate by Passenger Class')\n",
    "ax2.set_xlabel('Passenger Class')\n",
    "ax2.set_ylabel('Survival Rate (%)')\n",
    "ax2.tick_params(axis='x', rotation=0)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 👶 Age Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age analysis\n",
    "print(\"👶 AGE ANALYSIS\")\n",
    "print(\"=\" * 15)\n",
    "print(f\"Age statistics:\")\n",
    "print(titanic_data['Age'].describe())\n",
    "print(f\"\\nMissing age values: {titanic_data['Age'].isnull().sum()} ({titanic_data['Age'].isnull().sum()/len(titanic_data)*100:.1f}%)\")\n",
    "\n",
    "# Visualize age distribution\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Age histogram\n",
    "titanic_data['Age'].hist(bins=30, ax=ax1, alpha=0.7, color='skyblue')\n",
    "ax1.set_title('Age Distribution')\n",
    "ax1.set_xlabel('Age')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Age by survival\n",
    "survived_ages = titanic_data[titanic_data['Survived'] == 1]['Age'].dropna()\n",
    "not_survived_ages = titanic_data[titanic_data['Survived'] == 0]['Age'].dropna()\n",
    "\n",
    "ax2.hist([not_survived_ages, survived_ages], bins=30, alpha=0.7, \n",
    "         label=['Did not survive', 'Survived'], color=['red', 'green'])\n",
    "ax2.set_title('Age Distribution by Survival')\n",
    "ax2.set_xlabel('Age')\n",
    "ax2.set_ylabel('Frequency')\n",
    "ax2.legend()\n",
    "\n",
    "# Box plot of age by survival\n",
    "titanic_data.boxplot(column='Age', by='Survived', ax=ax3)\n",
    "ax3.set_title('Age Distribution by Survival (Box Plot)')\n",
    "ax3.set_xlabel('Survived (0=No, 1=Yes)')\n",
    "ax3.set_ylabel('Age')\n",
    "\n",
    "# Age groups survival rate\n",
    "age_groups = pd.cut(titanic_data['Age'], bins=[0, 12, 18, 35, 60, 100], \n",
    "                   labels=['Child', 'Teen', 'Adult', 'Middle', 'Senior'])\n",
    "age_survival_rate = pd.crosstab(age_groups, titanic_data['Survived'], normalize='index')[1] * 100\n",
    "age_survival_rate.plot(kind='bar', ax=ax4, color='orange')\n",
    "ax4.set_title('Survival Rate by Age Group')\n",
    "ax4.set_xlabel('Age Group')\n",
    "ax4.set_ylabel('Survival Rate (%)')\n",
    "ax4.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 💰 Fare Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fare analysis\n",
    "print(\"💰 FARE ANALYSIS\")\n",
    "print(\"=\" * 15)\n",
    "print(f\"Fare statistics:\")\n",
    "print(titanic_data['Fare'].describe())\n",
    "print(f\"\\nMissing fare values: {titanic_data['Fare'].isnull().sum()}\")\n",
    "\n",
    "# Visualize fare distribution\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Fare histogram\n",
    "titanic_data['Fare'].hist(bins=50, ax=ax1, alpha=0.7, color='gold')\n",
    "ax1.set_title('Fare Distribution')\n",
    "ax1.set_xlabel('Fare')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Log fare (to handle skewness)\n",
    "log_fare = np.log1p(titanic_data['Fare'])\n",
    "log_fare.hist(bins=30, ax=ax2, alpha=0.7, color='lightcoral')\n",
    "ax2.set_title('Log(Fare + 1) Distribution')\n",
    "ax2.set_xlabel('Log(Fare + 1)')\n",
    "ax2.set_ylabel('Frequency')\n",
    "\n",
    "# Fare by class\n",
    "titanic_data.boxplot(column='Fare', by='Pclass', ax=ax3)\n",
    "ax3.set_title('Fare Distribution by Passenger Class')\n",
    "ax3.set_xlabel('Passenger Class')\n",
    "ax3.set_ylabel('Fare')\n",
    "\n",
    "# Fare by survival\n",
    "titanic_data.boxplot(column='Fare', by='Survived', ax=ax4)\n",
    "ax4.set_title('Fare Distribution by Survival')\n",
    "ax4.set_xlabel('Survived (0=No, 1=Yes)')\n",
    "ax4.set_ylabel('Fare')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 Missing Values Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values analysis\n",
    "print(\"🔍 MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 30)\n",
    "\n",
    "missing_values = titanic_data.isnull().sum()\n",
    "missing_percentage = (missing_values / len(titanic_data)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_values,\n",
    "    'Missing Percentage': missing_percentage\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "\n",
    "print(missing_df)\n",
    "\n",
    "# Visualize missing values\n",
    "if not missing_df.empty:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Missing values count\n",
    "    missing_df['Missing Count'].plot(kind='bar', ax=ax1, color='red')\n",
    "    ax1.set_title('Missing Values Count')\n",
    "    ax1.set_xlabel('Columns')\n",
    "    ax1.set_ylabel('Missing Count')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    # Missing values percentage\n",
    "    missing_df['Missing Percentage'].plot(kind='bar', ax=ax2, color='orange')\n",
    "    ax2.set_title('Missing Values Percentage')\n",
    "    ax2.set_xlabel('Columns')\n",
    "    ax2.set_ylabel('Missing Percentage (%)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"✅ No missing values found!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🏠 Housing Dataset Exploration\n",
    "\n",
    "Now let's explore the Boston Housing dataset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 Basic Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"🏠 HOUSING DATASET OVERVIEW\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Shape: {housing_data.shape}\")\n",
    "print(f\"Columns: {list(housing_data.columns)}\")\n",
    "print(\"\\n📊 Data Types:\")\n",
    "print(housing_data.dtypes)\n",
    "print(\"\\n📈 Basic Statistics:\")\n",
    "housing_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔍 First Look at the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"👀 First 5 rows of Housing dataset:\")\n",
    "housing_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🎯 Target Variable Analysis (House Prices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze house prices (MEDV)\n",
    "print(\"🎯 HOUSE PRICE ANALYSIS\")\n",
    "print(\"=\" * 25)\n",
    "print(f\"Price statistics (in $1000s):\")\n",
    "print(housing_data['MEDV'].describe())\n",
    "\n",
    "# Visualize price distribution\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Price histogram\n",
    "housing_data['MEDV'].hist(bins=30, ax=ax1, alpha=0.7, color='lightblue')\n",
    "ax1.set_title('House Price Distribution')\n",
    "ax1.set_xlabel('Price ($1000s)')\n",
    "ax1.set_ylabel('Frequency')\n",
    "\n",
    "# Box plot\n",
    "housing_data['MEDV'].plot(kind='box', ax=ax2)\n",
    "ax2.set_title('House Price Box Plot')\n",
    "ax2.set_ylabel('Price ($1000s)')\n",
    "\n",
    "# Price by number of rooms\n",
    "ax3.scatter(housing_data['RM'], housing_data['MEDV'], alpha=0.6, color='green')\n",
    "ax3.set_title('Price vs Number of Rooms')\n",
    "ax3.set_xlabel('Average Number of Rooms (RM)')\n",
    "ax3.set_ylabel('Price ($1000s)')\n",
    "\n",
    "# Price by crime rate\n",
    "ax4.scatter(housing_data['CRIM'], housing_data['MEDV'], alpha=0.6, color='red')\n",
    "ax4.set_title('Price vs Crime Rate')\n",
    "ax4.set_xlabel('Crime Rate (CRIM)')\n",
    "ax4.set_ylabel('Price ($1000s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🔗 Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"🔗 CORRELATION ANALYSIS\")\n",
    "print(\"=\" * 25)\n",
    "\n",
    "# Calculate correlation with target variable\n",
    "correlations = housing_data.corr()['MEDV'].sort_values(ascending=False)\n",
    "print(\"Correlation with house prices (MEDV):\")\n",
    "print(correlations)\n",
    "\n",
    "# Visualize correlation matrix\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 8))\n",
    "\n",
    "# Full correlation heatmap\n",
    "sns.heatmap(housing_data.corr(), annot=True, cmap='coolwarm', center=0, ax=ax1)\n",
    "ax1.set_title('Feature Correlation Heatmap')\n",
    "\n",
    "# Correlation with target variable\n",
    "correlations.plot(kind='barh', ax=ax2, color='steelblue')\n",
    "ax2.set_title('Correlation with House Prices (MEDV)')\n",
    "ax2.set_xlabel('Correlation Coefficient')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📊 Feature Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions of all numerical features\n",
    "numerical_features = housing_data.select_dtypes(include=[np.number]).columns\n",
    "n_features = len(numerical_features)\n",
    "n_cols = 4\n",
    "n_rows = (n_features + n_cols - 1) // n_cols\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(20, 5*n_rows))\n",
    "axes = axes.flatten() if n_rows > 1 else [axes] if n_cols == 1 else axes\n",
    "\n",
    "for i, feature in enumerate(numerical_features):\n",
    "    housing_data[feature].hist(bins=30, ax=axes[i], alpha=0.7)\n",
    "    axes[i].set_title(f'{feature} Distribution')\n",
    "    axes[i].set_xlabel(feature)\n",
    "    axes[i].set_ylabel('Frequency')\n",
    "\n",
    "# Hide empty subplots\n",
    "for i in range(n_features, len(axes)):\n",
    "    axes[i].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🔍 Data Quality Assessment\n",
    "\n",
    "Let's use our custom DataValidator to assess data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize data validator\n",
    "validator = DataValidator()\n",
    "\n",
    "# Validate Titanic dataset\n",
    "print(\"🔍 VALIDATING TITANIC DATASET\")\n",
    "print(\"=\" * 35)\n",
    "titanic_validation = validator.validate_dataset(titanic_data, 'titanic')\n",
    "validator.print_validation_summary('titanic')\n",
    "\n",
    "print(\"\\n\" + \"=\"*70 + \"\\n\")\n",
    "\n",
    "# Validate Housing dataset\n",
    "print(\"🔍 VALIDATING HOUSING DATASET\")\n",
    "print(\"=\" * 35)\n",
    "housing_validation = validator.validate_dataset(housing_data, 'housing')\n",
    "validator.print_validation_summary('housing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📊 Summary and Key Insights\n",
    "\n",
    "Let's summarize our key findings from the data exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"📊 KEY INSIGHTS FROM DATA EXPLORATION\")\n",
    "print(\"=\" * 45)\n",
    "\n",
    "print(\"\\n🚢 TITANIC DATASET INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"• Dataset size: {titanic_data.shape[0]} passengers, {titanic_data.shape[1]} features\")\n",
    "print(f\"• Survival rate: {titanic_data['Survived'].mean()*100:.1f}%\")\n",
    "print(f\"• Gender impact: Women had {pd.crosstab(titanic_data['Sex'], titanic_data['Survived'], normalize='index')[1]['female']*100:.1f}% survival rate\")\n",
    "print(f\"• Class impact: 1st class had {pd.crosstab(titanic_data['Pclass'], titanic_data['Survived'], normalize='index')[1][1]*100:.1f}% survival rate\")\n",
    "print(f\"• Missing data: Age ({titanic_data['Age'].isnull().sum()} missing), Cabin ({titanic_data['Cabin'].isnull().sum()} missing)\")\n",
    "\n",
    "print(\"\\n🏠 HOUSING DATASET INSIGHTS:\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"• Dataset size: {housing_data.shape[0]} houses, {housing_data.shape[1]} features\")\n",
    "print(f\"• Price range: ${housing_data['MEDV'].min():.1f}k - ${housing_data['MEDV'].max():.1f}k\")\n",
    "print(f\"• Average price: ${housing_data['MEDV'].mean():.1f}k\")\n",
    "print(f\"• Strongest positive correlation with price: {housing_data.corr()['MEDV'].drop('MEDV').idxmax()} ({housing_data.corr()['MEDV'].drop('MEDV').max():.3f})\")\n",
    "print(f\"• Strongest negative correlation with price: {housing_data.corr()['MEDV'].drop('MEDV').idxmin()} ({housing_data.corr()['MEDV'].drop('MEDV').min():.3f})\")\n",
    "print(f\"• Missing data: {housing_data.isnull().sum().sum()} total missing values\")\n",
    "\n",
    "print(\"\\n🎯 NEXT STEPS:\")\n",
    "print(\"-\" * 15)\n",
    "print(\"• Handle missing values in Titanic dataset (Age, Cabin)\")\n",
    "print(\"• Engineer new features (family size, title extraction, etc.)\")\n",
    "print(\"• Handle outliers in both datasets\")\n",
    "print(\"• Scale numerical features for modeling\")\n",
    "print(\"• Encode categorical variables\")\n",
    "print(\"• Split data for training and testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 🎉 Congratulations!\n",
    "\n",
    "You've successfully completed the data exploration tutorial! You now understand:\n",
    "\n",
    "✅ How to load and examine datasets  \n",
    "✅ Basic statistical analysis and visualization  \n",
    "✅ Target variable analysis  \n",
    "✅ Missing value identification  \n",
    "✅ Correlation analysis  \n",
    "✅ Data quality assessment  \n",
    "\n",
    "### 🚀 Next Tutorial\n",
    "In the next notebook (`02_feature_engineering.ipynb`), we'll learn how to:\n",
    "- Handle missing values\n",
    "- Create new features\n",
    "- Encode categorical variables\n",
    "- Scale numerical features\n",
    "- Select important features\n",
    "\n",
    "### 💡 Practice Exercises\n",
    "Try these exercises to reinforce your learning:\n",
    "1. Create additional visualizations for the Titanic dataset\n",
    "2. Analyze the relationship between fare and survival\n",
    "3. Explore the housing dataset's geographical features\n",
    "4. Create your own data quality metrics\n",
    "\n",
    "Happy exploring! 🎊"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}